# ModSecurity rules for blocking robots
# ---------------------------------------------------------------
# Range: 2000600-2000699

# Bug in Applekit automation (ex: Jooble.org)
RewriteCond %{QUERY_STRING} "^newtab=true$"
 RewriteRule "(.*)" "$1?" [R=permanent,L,DPI]

# Previously detected vulnerability scanners
DefineStr VulnScanActionsP5 "t:none,~{warn},~{increaseBlockCounterMax},tag:VulnScan,setvar:IP.VulnScan,msg:'Vulnerability scanner'"
DefineStr VulnScanActions   "~{VulnScanActionsP5},~{drop404},msg:'Vulnerability scanner'"

# User-Agents ------------------------------------------------------------------
<IfDefine UACache>
 Use SecRule IP:knownUA "@contains %{TX.hash_ua}" "phase:1,t:none,tag:security,~{skipAfter}:AfterUATests,setvar:TX.knownUA"
 Use SecRule TX:knownUA @unconditionalMatch       "phase:2,t:none,tag:security,~{skipAfter}:AfterUATests"
</IfDefine>

 # We don't store bad UA because perf is not important for bad agents
 DefineStr BadUAActions_ "phase:2,t:none,~{status404},msg:'Invalid user-agent',tag:security,tag:bot,severity:ALERT"
 DefineStr BadUAActions  "~{BadUAActions_}"

 # User-agents that should be ignored (useless probes)
 # Microsoft Windows Network Diagnostics (ignore)
 Use SecRuleUseragent "Microsoft Windows Network Diagnostics"       2000622 "phase:1,~{stop404},msg:'Microsoft Windows Network Diagnostics'"
 # Microsoft Windows live probe (ignore)
 Use SecRuleUseragent "Windows-Live-Social-Object-Extractor-Engine" 2000623 "phase:1,~{stop404},msg:'Microsoft Live probe'"
 # iOS Exchange client
 Use SecRuleUseragent "AppleExchangeWebServices"                    2000624 "phase:1,~{stop404},msg:'iOS Exchange client',tag:Exchange"
 # Google-Read-Aloud
 Use SecRuleUseragent "Google-Read-Aloud"                           2000625 "phase:1,~{stop404},msg:'Google-Read-Aloud'"

 # Exploits
 Use SecRuleUseragent "@pmf ~{ConfPath}/common/security/exploits.data"  2000670 "~{BadUAActions},phase:1,msg:'Known malicious User-Agent'"

 # Browsers
 Use UseragentDetect "\b(?:Chrome|Edge?|Firefox|OPR|Safari|Trident|UCBrowser)/[0-9]" "knownBrowser"

 # Search engines, archive, statistic, ... -----------------------------------------------------------------
 # Safari sometimes masquerades as Facebook & Twitter
 Use SecRuleUseragent "Safari.*facebookexternalhit" 2000626 "phase:1,~{skipAfter}:EndOfCheckBots"
  Use UseragentDetect "@pmf ~{ConfPath}/common/security/search.data"     "knownSE"
  Use UseragentDetect "Feedfetcher-Google"                               "knownFeed"
  Use UseragentDetect "AdsBot-Google"                                    "knownAnalytics"
  Use UseragentDetect "@pmf ~{ConfPath}/common/security/api.data"        "knownApi"
  Use UseragentDetect "@pmf ~{ConfPath}/common/security/archive.data"    "knownArchive"
  Use UseragentDetect "@pmf ~{ConfPath}/common/security/monitoring.data" "knownMonitor"
  # Performance monitors
  Use SecRule &REQUEST_HEADERS_NAMES:'/^(?i)x-datadog-/' "@gt 0" "phase:2,t:none,~{status404},~{noIncreaseBlockCounter},tag:AutomatedTools,msg:'Performance monitor tool'"
 Use SecMarker EndOfCheckBots

 # Register known bots & browsers
 Use SecAction "phase:1,~{nosecaction},setvar:TX.knownBot=+0%{TX.knownSE}%{TX.knownFeed}%{TX.knownAnalytics}%{TX.knownApi}%{TX.knownArchive}%{TX.knownMonitor}"

 # Allow Monitoring, API
 Use SecRule TX:knownApi     @unconditionalMatch "phase:1,t:none,tag:security,~{skipAfter}:AfterUATests"
 Use SecRule TX:knownApi     @unconditionalMatch "phase:2,t:none,tag:security,~{skipAfter}:AfterUATests"
 Use SecRule TX:knownMonitor @unconditionalMatch "phase:1,t:none,tag:security,~{skipAfter}:AfterUATests"
 Use SecRule TX:knownMonitor @unconditionalMatch "phase:2,t:none,tag:security,~{skipAfter}:AfterUATests"

 # Old browsers that shouldn't be used anymore (IE < 10, Chrome|Firefox < 80, AppleWebKit < 500)
 Use SecRuleUseragent "Sharepoint Active-X Upload Control" 2000627,tag:bot "~{skipAfter}:AfterUseragentOld"
  Use SecRuleUseragent "/[0-9]+[.][)]"                  2000618 "~{BadUAActions},msg:'Fake User-Agent (invalid version)'"
  Use SecRuleUseragent "win(?:dows)? ?9[58]"            2000613 "~{BadUAActions},msg:'Fake User-Agent (too old OS version)'"
  Use SecRuleUseragent "AppleWebKit/(?:..?|[0-4]..)[.]" 2000614 "~{BadUAActions},msg:'Fake User-Agent (too old AppleWebKit version)'"
  Use SecRuleUseragent "chrome/(?:.|[0-7].)[.]"         2000615 "~{BadUAActions},msg:'Fake User-Agent (too old browser version)'"
  Use SecRuleUseragent "firefox/(?:.|[0-5].)[.]"        2000616 "~{BadUAActions},msg:'Fake User-Agent (too old browser version)'"
  Use SecRuleUseragent "\bmsie [0-7][.]"                2000617 "~{BadUAActions},msg:'Fake User-Agent (too old browser version)'"
 Use SecMarker AfterUseragentOld,tag:security,tag:bot

 # The Mozilla/ specifier at the top of the User-Agent is always either 4.0 or 5.0
 #   but Adobe Reader & Jeeves mimics a Mozilla/3
 Use SecRuleUseragent "(?i:Acrobat|Jeeves/Teoma)" 2000692 "~{skipAfter}:AfterUseragentMozilla"
  Use SecRuleUseragent "^mozilla/(?![45][.]0 )"   2000692 "~{BadUAActions}"
 Use SecMarker AfterUseragentMozilla,tag:security,tag:bot

 # Blocking requests -----------------------

 # Slowloris HTTP DoS (http://ha.ckers.org/slowloris/)
 Use SecRuleDeny REQUEST_HEADERS:X-a @unconditionalMatch "phase:1,id:2000628,tag:DoS,~{BadUAActions},~{increaseBlockCounterMax},setvar:IP.dos=+1,msg:'Slowloris HTTP DoS'"
 #Use SecRuleUseragent "DDos Apache" 2000628,tag:DoS "~{BadUAActions},~{increaseBlockCounterMax},setvar:IP.dos=+1,msg:'Slowloris HTTP DoS'"

 # Fake User-agent
 Use SecRuleHeader USER-AGENT  "(?i)^user-agent:"  "~{VulnScanActions},phase:1,tag:Bot,tag:Colon,msg:'Fake User-Agent'"

 # Allow known bots if indexing is allowed
 Use SecRule TX:knownBot "!^0" "phase:1,t:none,chain,tag:security,~{skipAfter}:AfterUATests"
  Use SecRule ENV:allow_SE "@eq 1" ""
 Use SecRule TX:knownBot "!^0" "phase:2,t:none,chain,tag:security,~{skipAfter}:AfterUATests"
  Use SecRule ENV:allow_SE "@eq 1" ""

 # Block known bots
 Use SecRuleDeny TX:knownSE        @unconditionalMatch "~{BadUaActions_},msg:'Search engine, social media (harmless)',id:2000681"
 Use SecRuleDeny TX:knownFeed      @unconditionalMatch "~{BadUaActions_},msg:'Newsfeed bot (harmless)',id:2000685"
 Use SecRuleDeny TX:knownAnalytics @unconditionalMatch "~{BadUaActions_},msg:'GoogleAnalytics (harmless)',id:2000686"
 Use SecRuleDeny TX:knownArchive   @unconditionalMatch "~{BadUaActions_},msg:'Archiving/statistic bot (harmless)'"
 #Use SecRuleDeny TX:knownMonitor  @unconditionalMatch "~{BadUaActions_},msg:'Monitoring bot (harmless)'"
 # Known robots were blocked => skip several tests when in DetectionOnly
 Use SecRule TX:knownBot "!^0" "phase:2,t:none,tag:security,~{skipAfter}:AfterUATests"

 # MS WebDAV clients (ignore)
 Use SecRule ENV:mso_client        @unconditionalMatch "phase:2,t:none,id:2000679,~{status}:404,~{noIncreaseBlockCounter},severity:INFO,tag:Ignore,msg:'MS WebDAV client (ignore)'"

 # Spiders, crawlers, and bots
 Use SecRuleUseragent "@pmf ~{ConfPath}/common/security/bots_bad.data"    2000605,tag:noreport1 "~{BadUAActions},msg:'Known bad bot'"
 Use SecRuleUseragent "@pmf ~{ConfPath}/common/security/bots_known.data"  2000604,tag:noreport2 "~{BadUAActions},msg:'Known bot (harmless)',severity:INFO"
 Use SecRuleUseragent "Embedly"                                           2000612,tag:noreport2 "~{BadUAActions},msg:'Known bot (harmless)',severity:INFO"
 Use SecRuleUseragent "(?i:\bjbot\b|(?:mac|ram|educate|wep).?search|dart.?communications|(?:demo|full.?web|lite|production|franklin|missauga|missigua).?(?:bot|locat)|(?:industry|internet|iufw|lincoln|missouri|program).?(?:program|web|state|college|shareware))"  2000690,tag:noreport2 "~{BadUAActions},msg:'Known spider (harmless)',severity:INFO"

 # Web leachers
 Use SecRuleUseragent "@pmf ~{ConfPath}/common/security/leechers.data"  2000656,tag:noreport1 "~{BadUAActions},msg:'Known spider (harmless)',severity:INFO"

 # Image-grabbers 
 Use SecRuleUseragent "(?i:image.?(?:fetch|stripper|sucker)|acoirobot|flickbot|picsearch[.]com|webcollage)" 2000658,tag:Parano "~{BadUAActions},msg:'Known image spider (harmless)',severity:INFO"

 # e-mail collectors and spammers
 Use SecRuleUseragent "@pmf ~{ConfPath}/common/security/spam.data"                                2000671,tag:Parano,tag:noreport1 "~{BadUAActions},msg:'Known spam bot'"
 Use SecRuleUseragent "email ?(?:collect|harvest|magnet|reaper|siphon|wolf|xtractorpro|o browse)" 2000671,tag:Parano,tag:noreport1 "~{BadUAActions},msg:'Known spam bot'"
 Use SecRuleUseragent "(?i:grabber|extractor)"                                                    2000672,tag:Parano               "~{BadUAActions},msg:'Collector bot',severity:INFO"
 Use SecRuleUseragent "(?i)\b(?:digext\b|dts agent)\b|^foca$"                                     2000673,tag:noreport2            "~{BadUAActions},msg:'Known bot'"

 # Unknown bots
 Use SecRuleUseragent  "@pmf ~{ConfPath}/common/security/bots_unknown.data"  2000695 "~{BadUAActions},msg:'Unknown Bot'"

 # Invalid browsers UA (exception for Websense scanner)
 Use SecRule TX:remote_addr "^208[.]80[.]19[2-9]"            "phase:2,t:none,id:2000601,~{skipAfter}:AfterUseragentAnonymous,tag:security"
 Use SecRuleUseragent "^Opera/12[.]0[(]"                                        2000601,tag:Slash,tag:Parenthesis "~{skipAfter}:AfterUseragentAnonymous"
  Use SecRuleUseragent "^[a-zA-Z]+/[0-9.]+[(]|anonymous/666|[(]compatible-|xx$" 2000601,tag:Slash,tag:Parenthesis "~{BadUAActions}"
 Use SecMarker AfterUseragentAnonymous,tag:security,tag:bot

 # Unbalanced parenthesis
 Use SecRuleUseragent "anonymized by Abelssoft" 2000693 "~{skipAfter}:AfterUseragentUnclosed"
  Use SecRuleUseragent "[(][^)]+$"              2000693,tag:Parenthesis "~{BadUAActions},msg:'Unclosed parenthesis in User-Agent'"
 Use SecMarker AfterUseragentUnclosed,tag:security,tag:bot

 # Peer 2 peer programs
 Use SecRuleUseragent  "(?i:gnutella|edonkey|bittorrent)" 2000674,tag:noreport1 "~{BadUAActions},msg:'P2P client'"
 Use SecRuleUseragent  "(?i)\bkazaa"                      2000674,tag:noreport1 "~{BadUAActions},msg:'P2P client'"

 # Allow non-browsers if needed
 Use SecRule ENV:allow_nonBrowser @unconditionalMatch "phase:2,t:none,tag:security,tag:AutomatedTools,~{skipAfter}:AfterAutomatedTools"

 # All modern browsers support Brotli compression
 #Use SecRule &TX:knownBrowser "@eq 0"                         "phase:2,t:none,id:2000621,tag:AutomatedTools,tag:security,~{skipAfter}:AfterBrotli"
 #Use SecRule REMOTE_ADDR "~{RP_IP_Check}"                     "phase:2,t:none,id:2000621,tag:AutomatedTools,tag:security,~{skipAfter}:AfterBrotli"
 #  Use SecRuleDeny REQUEST_HEADERS:Accept-Encoding  "!\bbr\b" "phase:2,t:none,id:2000621,tag:AutomatedTools,msg:'Brotli not supported, fake browser',~{testRule},rev:20231030"
 #Use SecMarker AfterBrotli,tag:security

 # Allow non-browsers for images (cf. link inclusion in LinkedIn)
 Use SecRule ENV:allow_SE "@eq 1" "phase:2,t:none,tag:security,tag:AutomatedTools,~{skipAfter}:AfterAutomatedTools,chain"
  Use SecRule TX:BASENAME "[.]~{ImagesFileExt}$" "t:none"

  # Specific library (used by Ogone agent)
  Use SecRuleUseragent "(?i)indy library"  2000652,tag:AutomatedTools "msg:'Non-browser client (used by Ogone agent)'"

  # Download manager
  #Use SecRuleUseragent "(?i:download|flashget|leechget|getright|bitcomet)" 2000659,tag:AutomatedTools "~{BadUAActions}"

  # Non-browser
  Use SecEnforceHeader User-Agent  "2000607,tag:AutomatedTools,~{status404},msg:'No User-Agent'"
  Use SecRuleUseragent "https?://" "2000688,tag:AutomatedTools" "~{BadUAActions},msg:'Search engine or robot'"

  # Python orders headers in a specific way
  Use SecRule REQUEST_HEADERS:Connection "!^close$"      "phase:2,id:2000698,t:none,tag:AutomatedTools,tag:security,tag:Parano,~{caseSensitive},~{skipAfter}:AfterUseragentPython"
   Use SecRule REQUEST_HEADERS_NAMES @unconditionalMatch "phase:2,id:2000698,t:none,tag:AutomatedTools,tag:security,tag:Parano,~{nosecaction},setvar:'tx.header_order=%{tx.header_order}/%{matched_var}'"
    Use SecRule TX:HEADER_ORDER "^(?i)/Accept-Encoding/Host(?:/Keep-Alive)?(?:/User-Agent)(?:/Accept-Charset)?/Connection(?:/Referer)?(?:/Cache-Control)?$" \
                                                         "phase:2,id:2000698,t:none,tag:AutomatedTools,tag:Parano,~{drop404},msg:'Request Header Ordering Alert: Python program'"
  Use SecMarker AfterUseragentPython,tag:security,tag:AutomatedTools
  # Generic spiders/crawlers
  Use SecRuleUseragent "(?i:crawl|spider|finder)"  2000608,tag:AutomatedTools "~{BadUAActions},msg:'Spider/Crawler'"

  # Command-line or libraries
  Use SecRuleUseragent "(?i:appengine-google|//bsalsa.com|cgichk|crawler4j|dart:io|Google-Apps-Script|heritrix|http_get_vars|http-client|libwww|MauiBot|python|RestSharp|lumsites|tulipchain|ZappySysApp|zgrab)"  2000609,tag:AutomatedTools "~{BadUAActions},msg:'Non-browser client'"
  # \bpython-(?:request|(?:http|url)lib[0-9]*)\b
  Use SecRuleUseragent "\b(?i:ahc|curl|elinks|HTTPie|perl|php/|PostmanRuntime|RestSharp| ruby/|wget)\b" 2000609,tag:AutomatedTools "~{BadUAActions},msg:'Non-browser client'"
  # Some PHP, etc.
  Use SecRuleHeader Content-Type "boundary=xYzZY"  "t:none,id:2000610,tag:AutomatedTools,tag:Parano,tag:Equal"
  # Used by SVN, LinkedIn, etc.
  Use SecRuleUseragent "(?i)httpclient"  2000611,tag:AutomatedTools "~{BadUAActions},msg:'Non-browser client'"
 Use SecMarker AfterAutomatedTools,tag:security
 
 Use SecRuleUseragent "@pmf ~{ConfPath}/common/security/scanners.data"        2000665 "~{BadUAActions},~{VulnScanActions},msg:'Vulnerability scanner'"
 Use SecRuleUseragent "(?i:\b(?:lwp|mozilla/5.0 sf|newt|nmap)\b|sql.*inject)" 2000666 "~{BadUAActions},~{VulnScanActions},msg:'Vulnerability scanner'"

 <IfDefine UACache>
  Use SecRule TX:knownBot "^0" "phase:2,tag:security,~{nosecaction},setvar:'IP.knownUA=%{tx.hash_ua},%{IP.knownUA}'"
 </IfDefine>

Use SecMarker AfterUATests,tag:security

Use SecRuleHeaders    "(?i:p2p-agent|\bkazaa)"                "2000675,msg:'P2P client',tag:Bot,tag:noreport1" ""

# Internal search engine
Use SecRuleHeaders    "(?i)ilocal company search"   "2000678,msg:'Internal search engine',severity:ALERT,tag:Bot" ""

# --- Fingerprinting techniques ---
# Invalid request
Use SecRule REQUEST_LINE "(?i)^OPTIONS\s*+[*]"  "phase:1,t:none,~{increaseBlockCounterMax},~{drop404},tag:Star,tag:Bot,tag:noreport1,msg:'Fingerprinting'"

# Open proxies scanner
Use SecRule REQUEST_HEADERS:Referer "(?i)proxyradar" "phase:1,t:none,~{increaseBlockCounterMax},~{drop404},tag:Bot,tag:noreport1,msg:'Open proxies scanner'"

# Open proxies scanner
Use SecRule REQUEST_HEADERS_NAMES:'/^X-Hola-/' @unconditionalMatch "phase:1,t:none,~{AnonymProxyAction},msg:'Hola VPN (hola.org)',tag:Proxy,tag:noreport1"

# Linkedin: adds parameters to URL
RewriteCond "%{HTTP_REFERER}"   "linkedin[.]com"
 RewriteCond "%{QUERY_STRING}"  "^goback="
 RewriteRule "(.*)" "$1?"  [R,L,DPI]

# This library uses invalid multipart encoding
#Use SecRuleUseragent 2000629 "^AHC/" "phase:1,~{nosecaction},ctl:ruleRemoveById=2002907"

# "Request-Id: |987f27e6cf72405c8f4529160481bb09.0" 
Use SecRule REQUEST_HEADERS:User-Agent "AppInsights" "phase:1,id:2000630,t:none,tag:bot,~{nosecaction},ctl:'ruleRemoveTargetById=2002927;REQUEST_HEADERS:Request-Id',ctl:'ruleRemoveTargetById=2002930;REQUEST_HEADERS:Request-Id'"

# Some robots don't recognise GoogleAnalytics relative URL => not an attack
Use SecRule TX:knownBot "^0"              "phase:1,t:none,tag:security,~{skip}:1"
Use SecRule TX:url "/gtm[.](?:js|start)$" "phase:1,t:none,~{stopSecurity}"


# Vulnerability scanners -------------------------------------------------------
Use SecRule REQUEST_HEADERS_NAMES "(?i)acunetix" "id:2000682,~{VulnScanActions},msg:'Vulnerability scanner: Acunetix'"
Use SecRuleHeaders                "(?i)acunetix"    "2000682,~{VulnScanActions},msg:'Vulnerability scanner: Acunetix'" ""
#Use SecRuleArgs  "(?i:)injected_by_wvs some_inexistent_file www.acunetix.tst"  2000682,~{VulnScanActions},msg:'Vulnerability scanner: Acunetix'"
#Use SecRuleArgs  "(?i)qualysxss"                                               2000683,~{VulnScanActions},msg:'Vulnerability scanner: Qualys'"
#Use SecRuleArgs  "(?i)xss[(]"                                                  2000684,~{VulnScanActions},msg:'Vulnerability scanner'"
Use SecRuleHeaders       "(?i)burpcollaborator"   "2000603,~{VulnScanActions},msg:'Vulnerability scanner: Burp'" ""
Use SecRuleHeader X-WIPP @unconditionalMatch   "id:2000606,~{VulnScanActions},tag:Dash,msg:'Vulnerability scanner: WebInspect'"

# https://www.qualys.com/support/faq/pci/
Use SecRuleIp  "@ipMatch 64.39.96.0/20,139.87.112.0/23" "phase:2,t:none,id:2000691,~{VulnScanActions},setvar:tx.vulnscan=qualys,tag:qualys"
# Tenable (Nessus)
DefineStr IpTenable  "@ipMatch 18.168.180.128/25,103.21.246.0/22,162.159.129.83,162.159.130.83,162.159.140.26,172.66.0.26,198.101.134.0/22"
Use SecRuleIp  "~{IpTenable}" "phase:2,t:none,id:2000694,~{VulnScanActions},setvar:tx.vulnscan=tenable,tag:tenable"
# Intruder.io
DefineStr IpIntruder "@ipMatch 3.9.159.128/25,3.26.100.0/24,3.67.7.128/25,3.98.92.0/25,3.106.118.128/25,3.108.37.0/24,3.124.123.128/25,3.132.217.0/25,3.251.224.0/24,13.56.21.128/25,13.56.21.128/25,13.59.252.0/25,13.115.104.128/25,13.210.1.64/26,15.228.125.0/24,18.116.198.0/24,18.168.180.128/25,18.168.224.128/25,18.194.95.64/26,35.73.219.128/25,203.12.218.0/24,13.213.79.0/24,18.139.204.0/25,35.177.219.0/26,34.201.223.128/25,34.223.64.0/25,35.82.51.128/25,35.86.126.0/24,44.192.244.0/24,44.206.3.0/24,44.242.181.128/25,54.175.125.192/26,54.93.254.128/26,54.255.254.0/26"
Use SecRuleIp  "~{IpIntruder}"                   "phase:2,t:none,id:2000696,~{VulnScanActions},setvar:tx.vulnscan=intruder,tag:intruder"
Use SecRuleUseragent "^Mozilla/5.0 [(]X11; Intruder;" 2000619,tag:intruder "~{VulnScanActions},setvar:tx.vulnscan=intruder"
# boardofcyber.io
Use SecRuleIp  "^20[.]74[.]22[.]207"             "phase:2,t:none,id:2000629,~{VulnScanActions},setvar:tx.vulnscan=boardofcyber,tag:boardofcyber"

# Phase 5 as the URL doesn't hurt
<Macro VulnScanUrl   @url $id $name>
 Use SecRuleUrlPhase @url $id,tag:VulnScan "~{VulnScanActionsP5},msg:'Vulnerability scanner: $name'" 5
</Macro>
Use SecRule IP:VulnScan @unconditionalMatch "phase:5,t:none,tag:security,~{skipAfter}:AfterVulnScan"
 Use VulnScanUrl "/antidisestablishmentarianism"   2000600 "httprint"
 Use VulnScanUrl "thereIsNoWayThat-You-CanBeThere" 2000697 "dirbuster"
 Use VulnScanUrl "/w00tw00t"                       2000602 "ZmEu/DFind"
Use SecMarker AfterVulnScan,tag:security,tag:VulnScan

# Reset counters of monitoring bots --------------------------------------------
SecRule &IP:monitor_ip "@eq 0" "phase:5,t:none,tag:security,~{skipAfter}:AfterIP"
 Use SecResetIPCounter @unconditionalMatch
Use SecMarker AfterIP,tag:security
